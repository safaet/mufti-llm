{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8P5KSXlD2/HhhfHz8/Av2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safaet/mufti-llm/blob/main/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyw_kbb_z2zu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example training text\n",
        "text = \"hello world\""
      ],
      "metadata": {
        "id": "uS_CGnug0G3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary\n",
        "chars = sorted(set(text))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}"
      ],
      "metadata": {
        "id": "-ukUJ8ZP0USY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"stoi = \", stoi)\n",
        "print(\"itos = \", itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSioPLm_13rc",
        "outputId": "af8e8024-2b63-4387-cc15-5447cd42cb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stoi =  {' ': 0, 'd': 1, 'e': 2, 'h': 3, 'l': 4, 'o': 5, 'r': 6, 'w': 7}\n",
            "itos =  {0: ' ', 1: 'd', 2: 'e', 3: 'h', 4: 'l', 5: 'o', 6: 'r', 7: 'w'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode text as integers\n",
        "def encode(s): return [stoi[c] for c in s]\n",
        "def decode(l): return ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)"
      ],
      "metadata": {
        "id": "T_uUmuPr07FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NnIdJxu2k7r",
        "outputId": "e63a8d1f-b3b7-4122-b6ed-934653b34025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 2, 4, 4, 5, 0, 7, 5, 6, 4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiny Dataset Loader"
      ],
      "metadata": {
        "id": "vBc-oS3y7O_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training samples\n",
        "def get_batch(seq_len=4):\n",
        "    ix = random.randint(0, len(data) - seq_len - 1)\n",
        "    x = data[ix:ix + seq_len]\n",
        "    y = data[ix + 1:ix + seq_len + 1]\n",
        "    return x.unsqueeze(0), y.unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "O69W62Qg2mXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Mini GPT-like Model"
      ],
      "metadata": {
        "id": "PGmr4Qw17cT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=16):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.token_embedding(x)  # (B, T, C)\n",
        "        x = self.linear(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-KYaquvw7bXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training the Model"
      ],
      "metadata": {
        "id": "rXK8z42q7kz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TinyGPT(vocab_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train loop\n",
        "for step in range(1000):\n",
        "    x, y = get_batch()\n",
        "    logits = model(x)  # (B, T, vocab_size)\n",
        "    loss = loss_fn(logits.view(-1, vocab_size), y.view(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(f\"Step {step}, loss {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tJuDdFf7nmf",
        "outputId": "c32e5458-5304-4a9b-a826-b1326c7cb0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, loss 2.5056\n",
            "Step 100, loss 0.5925\n",
            "Step 200, loss 0.7400\n",
            "Step 300, loss 0.3668\n",
            "Step 400, loss 0.6539\n",
            "Step 500, loss 0.3085\n",
            "Step 600, loss 0.4347\n",
            "Step 700, loss 0.3061\n",
            "Step 800, loss 0.8848\n",
            "Step 900, loss 0.6265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generate Text"
      ],
      "metadata": {
        "id": "fyIq6cew7uha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, start_text='h', length=20):\n",
        "    model.eval()\n",
        "    context = torch.tensor([stoi[start_text]], dtype=torch.long).unsqueeze(0)\n",
        "    result = [start_text]\n",
        "\n",
        "    for _ in range(length):\n",
        "        logits = model(context)\n",
        "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "        next_id = torch.multinomial(probs, num_samples=1).item()\n",
        "        next_char = itos[next_id]\n",
        "        result.append(next_char)\n",
        "\n",
        "        context = torch.cat([context, torch.tensor([[next_id]])], dim=1)\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "print(generate(model, start_text='h'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3ceq_r07p8H",
        "outputId": "8d919765-13f2-442c-e546-98a3a9d31df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helllorlo wo wo wo wo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare/prepare.py\n",
        "\n",
        "https://github.com/berkerdemirel/GPT-from-scratch?utm_source=chatgpt.com\n",
        "\n",
        "https://github.com/karpathy/minGPT\n",
        "\n",
        "https://github.com/Hannibal046/nanoRWKV?utm_source=chatgpt.com\n",
        "\n",
        "https://github.com/endlessreform/nanogpt-candle"
      ],
      "metadata": {
        "id": "7WRtMi7C7zoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}